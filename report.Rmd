---
title: "R Notebook"
output: html_notebook
Link: https://archive.ics.uci.edu/ml/datasets/default%20of%20credit%20card%20clients
---
Reference:
https://github.com/zkneupper/Default-Prediction-Capstone/blob/master/notebooks/Data-Wrangling.ipynb
Emails with professor who provided the datasets:
https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset/discussion/34608
```{r warning=FALSE,message=FALSE}
library(plyr)
library(dplyr)
library(Hmisc)
library(ggpubr)
library(DMwR)
library(caret)
library(pROC)
library(ggplot2)
library(ggpubr)
```

## I. Introduction

## II. Business Understanding

## III. Data Understanding
This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables: 
X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. 
X2: Gender (1 = male; 2 = female). 
X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). 
X4: Marital status (1 = married; 2 = single; 3 = others). 
X5: Age (year). 
X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. 
X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. 
X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005. 


## IV. Data Exploration and Preparation

```{r}
model_dir = "models"
data_dir = "data"
```

Factorize the variables and give values meanningful names:
```{r}
### Loading data
data=read.csv(paste(data_dir,"default.csv",sep="/"), header = TRUE, sep = ",",na.strings = "NA")
# apply(data,2,function(x){sum(is.na(x))/length(x)*100})
# 1 = male; 2 = female
data$SEX = factor(mapvalues(data$SEX, from = c(1, 2), to = c("MALE", "FEMALE")))
# 1 = graduate school; 2 = university; 3 = high school; 4 = others
data$EDUCATION = factor(mapvalues(data$EDUCATION, from = c(0,1,2,3,4,5,6), to = c("others","graduate school", "university", "high school", "others", "others", "others")))
# 1 = married; 2 = single; 3 = divorced
data$MARRIAGE = factor(mapvalues(data$MARRIAGE, from = c(0,1,2,3), to = c("others", "married", "single","divorced")))
data$default.payment.next.month = factor(mapvalues(data$default.payment.next.month,from = c(0,1), to = c("no","yes")))
y = data$default.payment.next.month
data = data[,-dim(data)[2]]
data$y = y
```
Show basic statistics for all columns:
```{r}
str(data)
summary(data)
```
### (1) Visualizations
```{r}
for (col in names(data[,-c(1,dim(data)[2])])) {
    if(!is.factor(data[,col])) next
    p1 = ggplot(data, aes(data[,col], fill = y)) + geom_bar(position="fill") +
      labs(x = "Default?", y = col) +
      theme(axis.text.x=element_text(angle = -90, hjust = 0))
    p2 = ggplot(data, aes(data[,col], fill = y)) + geom_bar() +
      labs(x = "Default?", y = col) +
      theme(axis.text.x=element_text(angle = -90, hjust = 0))
    p3 = ggarrange(p1, p2, ncol = 2, nrow = 1, common.legend = TRUE)
    print(p3)
}
```

### (3) Data outliers
Box plots were created to see if there were any outliers that should be addressed.
```{r warning=FALSE,message=FALSE}
# box plot for all numeric input ~ y
draw_box_plot = function() {
  for (i in 2:(length(data)-1)) {
    col = colnames(data)[i];
    if(!is.numeric(data[,i])) next
    p1 = ggplot(data, aes(x=y, y=data[,i])) + 
      geom_boxplot(fill="slateblue", alpha=0.2) + 
      xlab("Default?") + ylab(col)
    p2 = ggplot(data, aes(x=data[,col],fill=y)) + geom_histogram(position = "fill") + xlab(col)
    p3 = ggarrange(p1, p2, ncol = 2, nrow = 1, common.legend = TRUE)
    print(p3)
  }
}
draw_box_plot()
```

### (4) Data Preprocessing

```{r warning=FALSE,message=FALSE}
set.seed(42)
split = createDataPartition(data$y, times = 1, p=0.25, list = F)
train = data[split,]
test = data[-split,]
train_x = train[,names(train)!="y"]
train_y = train$y
folds <- createFolds(train_y, k = 5)
myControl <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  savePredictions = TRUE,
  index = folds,
  verboseIter = F
)
```
## V. Modeling

### (2) Classification Tree

```{r}
if(!exists("model_rpart")) {
  model_rpart <- train(
  y ~ ., train,
  metric = "ROC",
  method = "rpart",
  trControl = myControl,
  tuneGrid = expand.grid(
    cp = seq(0,0.01,0.001)
  )
)
}
plot(model_rpart)
```

### (3) Naive Bayes

```{r}
if(!exists("model_nb")) {
  model_nb <- train(
  y ~ ., train,
  metric = "ROC",
  method = "naive_bayes",
  trControl = myControl
)
}
plot(model_nb)
```

### (4) Generalized Linear Model (glmnet):

```{r}
if(!exists("model_glmnet")) {
  model_glmnet <- caret::train(
  y ~ ., train,
  metric = "ROC",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = c(0,1),
    lambda = 10:0/50
  ),
  trControl = myControl
)
}
plot(model_glmnet)
```

### (5) glmnet with PCA preprocessing

```{r}
if(!exists("model_glmnet_pca")) {
  model_glmnet_pca <- train(
    y ~ ., train,
    metric = "ROC",
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = c(0,1),
      lambda = 10:0/50
    ),
    trControl = myControl,
    preProcess = c("zv", "nzv","center","scale","pca")
  )
}
plot(model_glmnet_pca)
```

### (6) glmnet with manual feature selection:


```{r}

```

### (7) Random Forest

```{r}
if(!exists("model_rf")) {
  model_rf <- caret::train(
  y ~ ., train,
  metric = "ROC",
  method = "ranger",
  importance = 'impurity',
  trControl = myControl,
  tuneGrid = expand.grid(
    mtry = seq(1,10,1),
    splitrule = c("gini","extratrees"),
    min.node.size = c(1)
  )
)
}
plot(model_rf)
```

## VI. Evaluation

```{r}
model_list = list(rf=model_rf,
                  glmnet=model_glmnet,
                  glmnet_pca=model_glmnet_pca,
                  rpart=model_rpart,
                  nb=model_nb
                  )
resamps <- resamples(model_list)
summary(resamps, metric = "ROC")
dotplot(resamps, metric = "ROC")
```

## VII. Deployment

## VIII. Conclusions
